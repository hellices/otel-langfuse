"""FastAPI Chat Agent with LangGraph - Teacher-Student Quiz System with OpenTelemetry"""
import asyncio
import json
from contextlib import asynccontextmanager
from pathlib import Path
from typing import Optional, AsyncGenerator
from uuid import uuid4

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

# OpenTelemetry + Traceloop for LLM tracing
from traceloop.sdk import Traceloop
from opentelemetry import trace

from langchain_core.messages import HumanMessage

from config import AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT_NAME, OTEL_EXPORTER_OTLP_ENDPOINT
from graph import (
    create_graph, 
    QuizPhase,
)

# Global
graph = None
# ì„¸ì…˜ë³„ ìƒíƒœ ì €ì¥ (phase, difficulty, subject ë“±)
session_states = {}


# OpenTelemetry tracer
tracer = None

def setup_opentelemetry():
    """OpenTelemetry + Traceloop ì´ˆê¸°í™” (LLM input/output ìº¡ì²˜)"""
    global tracer
    
    import os
    # Attribute ê¸¸ì´ ì œí•œ ëŠ˜ë¦¬ê¸° (ê¸°ë³¸ê°’ì´ ì‘ì•„ì„œ LLM ë©”ì‹œì§€ê°€ ì˜ë¦¼)
    os.environ.setdefault("OTEL_ATTRIBUTE_VALUE_LENGTH_LIMIT", "65535")
    # Traceloop content ìº¡ì²˜ í™œì„±í™”
    os.environ.setdefault("TRACELOOP_TRACE_CONTENT", "true")
    
    # Traceloop ì´ˆê¸°í™” - LangChain, OpenAI ë“± ìë™ ê³„ì¸¡
    # exporterë¥¼ ì§ì ‘ ìƒì„±í•˜ì—¬ OTel Collectorë¡œ ì „ì†¡
    from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
    
    otlp_exporter = OTLPSpanExporter(
        endpoint=OTEL_EXPORTER_OTLP_ENDPOINT,
        insecure=True,
    )
    
    Traceloop.init(
        app_name="teacher-student-quiz",
        disable_batch=False,
        exporter=otlp_exporter,
    )
    
    tracer = trace.get_tracer(__name__)
    
    print(f"âœ… OpenTelemetry + Traceloop initialized!")
    print(f"   OTLP Endpoint: {OTEL_EXPORTER_OTLP_ENDPOINT}")
    
    return tracer


@asynccontextmanager
async def lifespan(app: FastAPI):
    global graph, tracer
    try:
        # OpenTelemetry ì´ˆê¸°í™”
        tracer = setup_opentelemetry()
        
        graph = create_graph()
        print("âœ… LangGraph Teacher-Student Quiz Agent initialized!")
        print(f"   Endpoint: {AZURE_OPENAI_ENDPOINT}")
        print(f"   Deployment: {AZURE_OPENAI_DEPLOYMENT_NAME}")
    except Exception as e:
        print(f"âŒ Failed to initialize: {e}")
        raise e
    yield
    print("Shutting down...")


app = FastAPI(
    title="LangGraph Chat Agent",
    description="Chat agent powered by LangGraph and Azure OpenAI",
    version="1.0.0",
    lifespan=lifespan
)

# Static íŒŒì¼ ì„œë¹™
app.mount("/static", StaticFiles(directory=Path(__file__).parent / "static"), name="static")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = None  # ì„¸ì…˜ ID (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)


class ChatResponse(BaseModel):
    response: str
    session_id: str  # í´ë¼ì´ì–¸íŠ¸ê°€ ë‹¤ìŒ ìš”ì²­ì— ì‚¬ìš©í•  ì„¸ì…˜ ID


@app.get("/", response_class=HTMLResponse)
async def root():
    template_path = Path(__file__).parent / "templates" / "index.html"
    return template_path.read_text(encoding="utf-8")


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    if not graph:
        raise HTTPException(status_code=503, detail="Agent not initialized")
    
    try:
        # ì„¸ì…˜ ID ì²˜ë¦¬ (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
        session_id = request.session_id or str(uuid4())
        
        # ì„¸ì…˜ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ì´ˆê¸°í™”
        if session_id not in session_states:
            session_states[session_id] = {
                "phase": QuizPhase.SETUP,
                "difficulty": None,
                "subject": None,
                "round_count": 0,
            }
        
        current_state = session_states[session_id]
        user_input = request.message.strip()
        
        # LangGraph ë‚´ì¥ checkpointer ì‚¬ìš©
        config = {"configurable": {"thread_id": session_id}}
        
        # í˜„ì¬ phaseì— ë”°ë¥¸ ì²˜ë¦¬
        phase = current_state.get("phase", QuizPhase.SETUP)
        
        # ë¦¬ì…‹ ëª…ë ¹ ì²˜ë¦¬
        if any(word in user_input.lower() for word in ["ìƒˆë¡œ", "ë¦¬ì…‹", "reset", "ë‹¤ì‹œ", "ì²˜ìŒ"]):
            session_states[session_id] = {
                "phase": QuizPhase.SETUP,
                "difficulty": None,
                "subject": None,
                "round_count": 0,
            }
            current_state = session_states[session_id]
            phase = QuizPhase.SETUP
        
        # ë‹¤ìŒ ë¬¸ì œ ëª…ë ¹ ì²˜ë¦¬
        if phase == QuizPhase.COMPLETE and any(word in user_input.lower() for word in ["ë‹¤ìŒ", "ê³„ì†", "next", "continue", "ë”"]):
            phase = QuizPhase.QUESTIONING
            current_state["phase"] = phase
        
        # ê·¸ë˜í”„ invoke ì¤€ë¹„
        invoke_state = {
            "messages": [HumanMessage(content=user_input)],
            "user_input": user_input,
            "phase": phase,
            "difficulty": current_state.get("difficulty"),
            "subject": current_state.get("subject"),
            "round_count": current_state.get("round_count", 0),
        }
        
        # ê·¸ë˜í”„ ì‹¤í–‰
        result = graph.invoke(invoke_state, config=config)
        
        # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        session_states[session_id] = {
            "phase": result.get("phase", QuizPhase.SETUP),
            "difficulty": result.get("difficulty"),
            "subject": result.get("subject"),
            "round_count": result.get("round_count", 0),
        }
        
        # ëª¨ë“  ìƒˆ ë©”ì‹œì§€ ìˆ˜ì§‘
        all_responses = []
        for msg in result["messages"]:
            if hasattr(msg, 'content') and msg.content:
                # HumanMessageê°€ ì•„ë‹Œ ê²ƒë§Œ ìˆ˜ì§‘
                if not isinstance(msg, HumanMessage):
                    all_responses.append(msg.content)
        
        # ë§ˆì§€ë§‰ AI ì‘ë‹µ ë°˜í™˜ (ì—¬ëŸ¬ ê°œë©´ í•©ì¹¨)
        response_text = "\n\n".join(all_responses) if all_responses else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return ChatResponse(response=response_text, session_id=session_id)
    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """SSE ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ LangGraphë¥¼ í†µí•œ ì—ì´ì „íŠ¸ ëŒ€í™”ë¥¼ í† í° ë‹¨ìœ„ë¡œ ì‹¤ì‹œê°„ ì „ì†¡"""
    if not graph:
        raise HTTPException(status_code=503, detail="Agent not initialized")
    
    async def event_generator() -> AsyncGenerator[str, None]:
        try:
            # ì„¸ì…˜ ID ì²˜ë¦¬
            session_id = request.session_id or str(uuid4())
            
            # ì„¸ì…˜ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ì´ˆê¸°í™”
            if session_id not in session_states:
                session_states[session_id] = {
                    "phase": QuizPhase.SETUP,
                    "difficulty": None,
                    "subject": None,
                    "round_count": 0,
                }
            
            current_state = session_states[session_id]
            user_input = request.message.strip()
            
            phase = current_state.get("phase", QuizPhase.SETUP)
            
            # ì„¸ì…˜ ID ì „ì†¡
            yield f"data: {json.dumps({'type': 'session', 'session_id': session_id})}\n\n"
            
            # ë¦¬ì…‹ ëª…ë ¹ ì²˜ë¦¬
            if any(word in user_input.lower() for word in ["ìƒˆë¡œ", "ë¦¬ì…‹", "reset", "ë‹¤ì‹œ", "ì²˜ìŒ"]):
                session_states[session_id] = {
                    "phase": QuizPhase.SETUP,
                    "difficulty": None,
                    "subject": None,
                    "round_count": 0,
                }
                current_state = session_states[session_id]
                phase = QuizPhase.SETUP
            
            # ë‹¤ìŒ ë¬¸ì œ ëª…ë ¹ ì²˜ë¦¬
            if phase == QuizPhase.COMPLETE and any(word in user_input.lower() for word in ["ë‹¤ìŒ", "ê³„ì†", "next", "continue", "ë”"]):
                phase = QuizPhase.QUESTIONING
                current_state["phase"] = phase
            
            # LangGraph ì„¤ì •
            config = {
                "configurable": {"thread_id": session_id},
            }
            
            # OpenTelemetry spanìœ¼ë¡œ íŠ¸ë ˆì´ì‹±
            with tracer.start_as_current_span("chat_stream") as span:
                span.set_attribute("session_id", session_id)
                span.set_attribute("user_input", user_input)
                span.set_attribute("phase", phase)
            
                # ê·¸ë˜í”„ invoke ì¤€ë¹„
                invoke_state = {
                    "messages": [HumanMessage(content=user_input)],
                    "user_input": user_input,
                    "phase": phase,
                    "difficulty": current_state.get("difficulty"),
                    "subject": current_state.get("subject"),
                    "round_count": current_state.get("round_count", 0),
                }
                
                # astreamìœ¼ë¡œ LangGraph ì‹¤í–‰ (stream_mode="updates"ë¡œ ë…¸ë“œë³„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°)
                current_node = None
                node_labels = {
                    "teacher_question": "ğŸ‘¨â€ğŸ« Teacher (ë¬¸ì œ)",
                    "student_answer": "ğŸ§‘â€ğŸ“ Student",
                    "teacher_evaluate": "ğŸ‘¨â€ğŸ« Teacher (í‰ê°€)",
                }
                
                # stream_mode="updates"ë¡œ ë…¸ë“œë³„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°
                async for event in graph.astream(invoke_state, config=config, stream_mode="updates"):
                    for node_name, node_output in event.items():
                        with tracer.start_as_current_span(f"node_{node_name}") as node_span:
                            node_span.set_attribute("node_name", node_name)
                            print(f"[DEBUG] node={node_name}, output_keys={node_output.keys() if isinstance(node_output, dict) else 'not dict'}")
                            
                            # ë©”ì‹œì§€ ì¶”ì¶œ
                            if isinstance(node_output, dict) and "messages" in node_output:
                                for msg in node_output["messages"]:
                                    if hasattr(msg, "content") and msg.content:
                                        content = msg.content
                                        node_span.set_attribute("content_length", len(content))
                                        
                                        # ë…¸ë“œë³„ ë¼ë²¨ ì„¤ì •
                                        label = node_labels.get(node_name, node_name)
                                        if node_name == "teacher_question":
                                            rc = current_state.get("round_count", 0) + 1
                                            current_state["round_count"] = rc
                                            label = f"ğŸ‘¨â€ğŸ« Teacher (ë¬¸ì œ #{rc})"
                                        
                                        # ë…¸ë“œ ì‹œì‘ ì•Œë¦¼
                                        if node_name in node_labels:
                                            yield f"data: {json.dumps({'type': 'node_start', 'node': node_name, 'label': label}, ensure_ascii=False)}\n\n"
                                        
                                        # ì „ì²´ ë©”ì‹œì§€ ì „ì†¡ (íƒ€ì´í•‘ íš¨ê³¼ëŠ” í”„ë¡ íŠ¸ì—ì„œ)
                                        yield f"data: {json.dumps({'type': 'message', 'node': node_name, 'content': content}, ensure_ascii=False)}\n\n"
                                        
                                        # ë…¸ë“œ ì¢…ë£Œ
                                        if node_name in node_labels:
                                            yield f"data: {json.dumps({'type': 'node_end', 'node': node_name})}\n\n"
                                        
                                        # ë‹¤ìŒ ë…¸ë“œ ëŒ€ê¸° í‘œì‹œ
                                        if node_name == "setup" and "í€´ì¦ˆ ì„¤ì • ì™„ë£Œ" in content:
                                            yield f"data: {json.dumps({'type': 'waiting', 'message': 'ğŸ‘¨â€ğŸ« Teacherê°€ ë¬¸ì œë¥¼ ì¤€ë¹„ ì¤‘...'})}\n\n"
                                        elif node_name == "teacher_question":
                                            yield f"data: {json.dumps({'type': 'waiting', 'message': 'ğŸ§‘â€ğŸ“ Studentê°€ ìƒê° ì¤‘...'})}\n\n"
                                        elif node_name == "student_answer":
                                            yield f"data: {json.dumps({'type': 'waiting', 'message': 'ğŸ‘¨â€ğŸ« Teacherê°€ í‰ê°€ ì¤‘...'})}\n\n"
                                
                                        await asyncio.sleep(0.1)
            
            # ìµœì¢… ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
            final_state = graph.get_state(config)
            if final_state and final_state.values:
                session_states[session_id] = {
                    "phase": final_state.values.get("phase", QuizPhase.SETUP),
                    "difficulty": final_state.values.get("difficulty"),
                    "subject": final_state.values.get("subject"),
                    "round_count": final_state.values.get("round_count", 0),
                }
            
            # ì™„ë£Œ ì´ë²¤íŠ¸
            yield f"data: {json.dumps({'type': 'done'})}\n\n"
            
        except Exception as e:
            print(f"Streaming Error: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )


@app.get("/health")
async def health_check():
    return {"status": "healthy", "graph_initialized": graph is not None}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
